{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MetaCriticScraper import MetaCriticScraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "years = [i for i in range(2010, 2024)]\n",
    "\n",
    "for y in years:\n",
    "    year = y\n",
    "    hrd = {'User-Agent' : 'Mozilla/5.0', 'referer' : 'https://www.metacritic.com/browse/games/score/metascore/year/all/filtered?year_selected=' + year + '&distribution=&sort=desc&view=detailed'}\n",
    "    url = \"https://www.metacritic.com/browse/games/score/metascore/year/all/filtered?year_selected=\" + year + \"&distribution=&sort=desc&view=detailed\"\n",
    "\n",
    "    req = requests.get(url, headers=hrd)\n",
    "    # response = urllib.request.urlopen(url)\n",
    "\n",
    "    soup = BeautifulSoup(req.content, \"html.parser\", from_encoding='utf-8')\n",
    "    # results = soup.select(\"a\")  #id 아래에 strong을 가져오겠다\n",
    "    questions = soup.find(\"div\", {\"class\":\"title_bump\"})\n",
    "\n",
    "    d = list(questions.find_all(\"a\", class_=\"page_num\"))\n",
    "    # num_list = [str(int(item.string.strip())-1) for item in d]\n",
    "    url_num_list = [int(item.string.strip()) for item in d]\n",
    "\n",
    "    num_list = []\n",
    "    for i in range(url_num_list[len(url_num_list)-1]):\n",
    "        num_list.append(str(i))\n",
    "\n",
    "    game_urls = []\n",
    "    for j in range(len(num_list)):\n",
    "        hrd = {'User-Agent' : 'Mozilla/5.0', 'referer' : \"https://www.metacritic.com/browse/games/score/metascore/year/all/filtered?year_selected=\" + year + \"&distribution=&sort=desc&view=detailed\" + \"&page=\" + num_list[j] }\n",
    "        url = \"https://www.metacritic.com/browse/games/score/metascore/year/all/filtered?year_selected=\" + year + \"&distribution=&sort=desc&view=detailed\" + \"&page=\" + num_list[j]\n",
    "\n",
    "        req = requests.get(url, headers=hrd)\n",
    "        # response = urllib.request.urlopen(url)\n",
    "\n",
    "        soup = BeautifulSoup(req.content, \"html.parser\", from_encoding='utf-8')\n",
    "        # results = soup.select(\"a\")  #id 아래에 strong을 가져오겠다\n",
    "        # 게임 목록을 가져오기 위해 필요한 태그와 클래스를 확인합니다.\n",
    "        game_items = soup.find_all(\"td\", class_=\"clamp-summary-wrap\")\n",
    "\n",
    "        # 각 게임별 URL을 추출합니다.\n",
    "        \n",
    "        for item in game_items:\n",
    "            link = item.find(\"a\", class_=\"title\")\n",
    "            game_urls.append(link['href'])\n",
    "\n",
    "        df = pd.DataFrame(columns=['name', 'platform','publisher', 'rating', 'genre', '#_of_player', 'release_date', 'critic_score', 'critic_count', 'user_score', 'user_count','img_url', 'description'])\n",
    "\n",
    "    for i in game_urls:\n",
    "        url = 'https://www.metacritic.com' + i\n",
    "        scraper = MetaCriticScraper(url)\n",
    "        df = pd.concat([df, pd.DataFrame([{'name' : scraper.game['title'], 'platform': scraper.game['platform'], 'publisher':scraper.game['publisher'],\n",
    "                            'rating': scraper.game['rating'] , 'genre':scraper.game['genre'] , \n",
    "                            '#_of_player':scraper.game['nplayer'] , 'release_date':scraper.game['release_date'] , 'critic_score':scraper.game['critic_score'] , \n",
    "                            'critic_count':scraper.game['critic_count'], 'user_score':scraper.game['user_score'] , 'user_count':scraper.game['user_count'], \n",
    "                            'img_url':scraper.game['image'] , 'description':scraper.game['description']}])], ignore_index=True)\n",
    "    \n",
    "    filename = year + '_raw.csv'  # 파일 이름 생성\n",
    "    df.to_csv('./data/' + filename, index=False)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr = pd.read_csv('./data/' + filename)\n",
    "df_pr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr['#_of_player'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr[df_pr['#_of_player'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_pr_pr = df_pr.groupby('name').agg({\n",
    "    'platform': lambda x: ', '.join(x[x.notnull()]),\n",
    "    'publisher': lambda x: next(iter(x[x.notnull()]), np.nan),\n",
    "    'rating': lambda x: next(iter(x[x.notnull()]), np.nan),\n",
    "    'genre': lambda x: next(iter(x[x.notnull()]), np.nan),\n",
    "    '#_of_player': lambda x: next(iter(x[x.notnull()]), np.nan),\n",
    "    'release_date': lambda x: next(iter(x[x.notnull()]), np.nan),\n",
    "    'critic_score': lambda x: next(iter(x[x.notnull()]), np.nan),\n",
    "    'critic_count': lambda x: next(iter(x[x.notnull()]), np.nan),\n",
    "    'user_score': lambda x: next(iter(x[x.notnull()]), np.nan),\n",
    "    'user_count': lambda x: next(iter(x[x.notnull()]), np.nan),\n",
    "    'img_url': lambda x: next(iter(x[x.notnull()]), np.nan),\n",
    "    'description': lambda x: next(iter(x[x.notnull()]), np.nan)\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr_pr.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr[df_pr['#_of_player'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr_pr[df_pr_pr['#_of_player'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr[df_pr['genre'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(host = \"34.125.124.136\", dbname=\"game\", user=\"test\", password=\"1234\", port=5432)\n",
    "cur = conn.cursor()\n",
    "\n",
    "\n",
    "cur.execute('''\n",
    "                CREATE TABLE IF NOT EXISTS metacritic_game (id SERIAL PRIMARY KEY,\n",
    "                                                name VARCHAR(20),\n",
    "                                                platform VARCHAR(20),\n",
    "                                                ranking_of_year NUMERIC(20),\n",
    "                                                genre VARCHAR(255),\n",
    "                                                _of_player VARCHAR(255),\n",
    "                                                release_data VARCHAR(255),\n",
    "                                                critic_score NUMERIC(255),\n",
    "                                                user_score NUMERIC(255),\n",
    "                                                user_count NUMERIC(255),\n",
    "                                                img_url VARCHAR(255),\n",
    "                                                description VARCHAR(255));          \n",
    "            ''')\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"postgresql://test:1234@34.125.124.136:5432/game\")\n",
    "df.to_sql(\"metacritic_game\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"DROP TABLE craling_data_test\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(columns=['name', 'platform', 'ranking_of_year', 'genre', '#_of_player', 'release_date', 'critic_score', 'critic_count', 'user_score', 'user_count','img_url', 'description'])\n",
    "\n",
    "# hrd = {'User-Agent' : 'Mozilla/5.0', 'referer' : \"https://www.metacritic.com/browse/games/score/metascore/year/all/filtered?year_selected=2023&distribution=&sort=desc&view=detailed\" }\n",
    "# url = \"https://www.metacritic.com/browse/games/score/metascore/year/all/filtered?year_selected=2023&distribution=&sort=desc&view=detailed\"\n",
    "\n",
    "# req = requests.get(url, headers=hrd)\n",
    "# # response = urllib.request.urlopen(url)\n",
    "\n",
    "# soup = BeautifulSoup(req.content, \"html.parser\", from_encoding='utf-8')\n",
    "# # results = soup.select(\"a\")  #id 아래에 strong을 가져오겠다\n",
    "# questions = soup.find(\"div\", {\"class\":\"title_bump\"})\n",
    "\n",
    "# a = questions.select(\"h3\")\n",
    "# name_list = [item.string for item in a]\n",
    "\n",
    "# b = list(questions.find_all(\"span\", {\"class\":\"data\"}))\n",
    "# platform_list = [item.string.strip() for item in b]\n",
    "\n",
    "# url_name_list = []\n",
    "# for i in range(len(name_list)):\n",
    "#     url_name = name_list[i].lower().replace(' ', '-')\n",
    "#     url_name = url_name.replace(\"'\", '')\n",
    "#     url_name = url_name.replace(\".\", '')\n",
    "#     url_name_list.append(url_name.lower().replace(':', '')) \n",
    "\n",
    "# url_platform_list = []\n",
    "# for i in range(len(platform_list)):\n",
    "#     url_platform_list.append(platform_list[i].lower().replace(' ', '-'))\n",
    "\n",
    "\n",
    "# url_list = []\n",
    "# for i in range(len(name_list)):\n",
    "#     url_list.append(\"https://www.metacritic.com/game/\" + url_platform_list[i]  + \"/\" + url_name_list[i] )\n",
    "\n",
    "# c = list(questions.find_all(\"span\", {\"class\":\"title numbered\"}))\n",
    "# ranking_list = [(item.string.strip()).replace('.','') for item in c]\n",
    "\n",
    "# for i in range(len(url_list)):\n",
    "#     scraper = MetaCriticScraper(url_list[i])\n",
    "#     try:\n",
    "#         cur.execute(\"INSERT INTO craling_data_test VALUES (%s, %s, %s, %d, %s, %s, %s, %f, %f, %f, %s, %s);\",  )\n",
    "#         conn.commit()\n",
    "#     except:\n",
    "#         conn.rollback()\n",
    "        \n",
    "#     df = df.append({'name' : scraper.game['title'], 'platform': scraper.game['platform'], 'publisher':scraper.game['publisher'],'rating': scraper.game['rating'] ,'ranking_of_year':ranking_list[i] , 'genre':scraper.game['genre'] , '#_of_player':scraper.game['nplayer'] , 'release_date':scraper.game['release_date'] , 'critic_score':scraper.game['critic_score'] , 'critic_count':scraper.game['critic_count'], 'user_score':scraper.game['user_score'] , 'user_count':scraper.game['user_count'], 'img_url':scraper.game['image'] , 'description':scraper.game['description'] }, ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['name', 'platform', 'ranking_of_year', 'genre', '#_of_player', 'release_date', 'critic_score', 'critic_count', 'user_score', 'user_count','img_url', 'description'])\n",
    "for j in range(len(num_list)):\n",
    "    hrd = {'User-Agent' : 'Mozilla/5.0', 'referer' : \"https://www.metacritic.com/browse/games/score/metascore/year/all/filtered?year_selected=2023&distribution=&sort=desc&view=detailed\" + \"&page=\" + num_list[j] }\n",
    "    url = \"https://www.metacritic.com/browse/games/score/metascore/year/all/filtered?year_selected=2023&distribution=&sort=desc&view=detailed\" + \"&page=\" + num_list[j]\n",
    "\n",
    "    req = requests.get(url, headers=hrd)\n",
    "    # response = urllib.request.urlopen(url)\n",
    "\n",
    "    soup = BeautifulSoup(req.content, \"html.parser\", from_encoding='utf-8')\n",
    "    # results = soup.select(\"a\")  #id 아래에 strong을 가져오겠다\n",
    "    questions = soup.find(\"div\", {\"class\":\"title_bump\"})\n",
    "\n",
    "    a = questions.select(\"h3\")\n",
    "    name_list = [item.string for item in a]\n",
    "\n",
    "    b = list(questions.find_all(\"span\", {\"class\":\"data\"}))\n",
    "    platform_list = [item.string.strip() for item in b]\n",
    "\n",
    "    url_name_list = []\n",
    "    for i in range(len(name_list)):\n",
    "        url_name = name_list[i].lower().replace(' ', '-')\n",
    "        url_name = url_name.replace(\"'\", '')\n",
    "        url_name = url_name.replace(\".\", '')\n",
    "        url_name_list.append(url_name.lower().replace(':', '')) \n",
    "\n",
    "    url_platform_list = []\n",
    "    for i in range(len(platform_list)):\n",
    "        url_platform_list.append(platform_list[i].lower().replace(' ', '-'))\n",
    "\n",
    "\n",
    "    url_list = []\n",
    "    for i in range(len(name_list)):\n",
    "        url_list.append(\"https://www.metacritic.com/game/\" + url_platform_list[i]  + \"/\" + url_name_list[i] )\n",
    "\n",
    "    c = list(questions.find_all(\"span\", {\"class\":\"title numbered\"}))\n",
    "    ranking_list = [(item.string.strip()).replace('.','') for item in c]\n",
    "\n",
    "    for i in range(len(url_list)):\n",
    "        scraper = MetaCriticScraper(url_list[i])\n",
    "        # try:\n",
    "        #     cur.execute(\"INSERT INTO craling_data_test VALUES (%s, %s, %s, %d, %s, %s, %s, %f, %f, %f, %s, %s);\",  )\n",
    "        #     conn.commit()\n",
    "        # except:\n",
    "        #     conn.rollback()\n",
    "        \n",
    "        df = df.append({'name' : scraper.game['title'], 'platform': scraper.game['platform'], 'publisher':scraper.game['publisher'],'rating': scraper.game['rating'] ,'ranking_of_year':ranking_list[i] , 'genre':scraper.game['genre'] , '#_of_player':scraper.game['nplayer'] , 'release_date':scraper.game['release_date'] , 'critic_score':scraper.game['critic_score'] , 'critic_count':scraper.game['critic_count'], 'user_score':scraper.game['user_score'] , 'user_count':scraper.game['user_count'], 'img_url':scraper.game['image'] , 'description':scraper.game['description'] }, ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('2022_new_new_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def keep_english_letters(text):\n",
    "    pattern = re.compile('[^a-zA-Z,]')\n",
    "    return re.sub(pattern, '', text)\n",
    "\n",
    "data['genre'] = data['genre'].apply(keep_english_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('2022_new_new.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
